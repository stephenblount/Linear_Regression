Automakers could benefit from a tool to predict the starting value of a newly created car based on the features of the car. The objective of this car data analysis is to collect and build multiple linear regression models to predict car price. The goal of the analysis is to reduce the error associated with the cost function as much as possible to produce the most effective regression model for prediction. The data was scraped from car-data.com and prepoccesed before regression models were fit. Multicollinearity and homoscedasticity were seen in the data and were attempted to be counteracted. A ridge regression model was found to have the highest accuracy of predicting the true car price. The results showed that the price of a car, the target variable, had a strong linear relationship with the horsepower of the engine. Other key features are torque, engine capacity and acceleration. The model had the highest accuracy when predicting car prices on the lower to mid range of the price scale. There are fewer data points for high values cars in the dataset leading to more unstable predictions.

Data was scraped from the website car-data.com using a combination of Selenium and BeautifulSoup. The website had 45 sitemaps, each containing over 10,000 urls for different cars. The decision was made to randomly select 25 cars from each of the 45 sitemaps producing roughly 1125 different cars. After data cleaning, the data frame contained roughly 900 rows and 15 features. SciKit-Learn, Pandas, Numpy and Seaborn were then used for data analysis and visualization. 

The first step in the data analysis process was exploratory data analysis. For this analysis rows were removed that contained miss, or blank data. To try to reduce model error extreme outliers were removed from the dataset where price was greater than $200,000 and less than $7,000. From pair plots of the numerical data, no features stood out that needed specific feature engineering. Heat maps of the numerical data showed a strong linear relationship between price, the target variable, and horsepower. Horsepower was also seen to have multicollinearity with a number of other numerical features that were also related to engine performance. These multicollinear features were left in the model with the intent that a LASSO regression and ridge regression model will reduce the effect of multicollinearity.

The initial car data analysis was designed to account for all variables numeric and categorical. Categorical data was converted to dummy variables adding 80 additional columns to the analysis. Data was then split into train, test and validation sets and a baseline linear regression model was created. Next, a Lasso regression model was created to reduce the number of features present in the model. Unimpactful features will have their coefficients reduced to zero, giving insight into which features should be removed from analysis. This process led to the removal of twenty features. 

After feature removal, a new linear regression model was created to capture the change in R2 adjusted. Finally, a ridge regression model was created to help reduce the coefficients of the multicollinear features. R2 adjusted and Mean Absolute Error (MAE) was calculated on the validation set for every regression model created. The analysis showed that the ridge regression model had the highest R2 adjusted (0.873) and lowest MAE ($5524), making ridge regression the chosen model for prediction. Diagnostic plots were then created from the ridge regression model, showing that the residual versus the predicted target variable was not homoscedastic. This was determined to be due to the fact that the price data was heavily right skewed, data points for higher priced cars were sparse. This led the model to be more accurate at predicting car price for cars in the mid to low range rather than luxury cars. 

Standardized feature coefficient values were output from the ridge regression model to find which features were the most impactful to the model prediction. The values showed that horsepower had a significantly higher coefficient compared to other features. Torque, engine capacity and acceleration were the next most impactful features, in that order. These features would be suggested to automobile manufacturers as strong metrics for predicting car price. Future modeling would benefit from collecting more data points for higher end cars to increase the modelâ€™s ability to predict the price of higher end cars. 
